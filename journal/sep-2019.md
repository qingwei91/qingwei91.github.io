# 01 to 03-09-2019

## What happened?

## How you feel?

## What have you learn?
* Having some sort of test bed is useful, I really need to figure out how to make sbt console behaves like ammonite repl, or scala 3 will solve this?? 

# 04-09-2019
## What happened?

## How you feel?

## What have you learn?
* You should not use Monad/Free monad if you want to capture all results of every steps in your tree unconditionally, ie. if you want every flatMap to execute and capture response in some ordered collection, Monad is likely not the right structure, because Free monad allow conditions

# 16-09-2019
## What happened?
A week after launch ~~

## How you feel?
Calm, but not sure what to focus on

## What have you learn?
* It is useful to think tech debt in terms of the scope it impacts, `Local`, `Global`, and `Systemic`
* When deciding boundary of each Cloudformation template, it is important to think about lifecycle, things that should live long should not live in things that are peripheral
 
# 20-09-2019
## What happened?
Past 3 days has been great, less pressure

## How you feel?
Good

## What have you learn?
* iota, a scala library that gives nice coproduct syntax, makes composing multiple stuff more practical
* using Free monad **might** make testing easier, but I am not sure, maybe you just shift complexity to the natural transformation?

### How JIT linearization works

There are 3 type of events
* `linearization` is an event happen on the data structure, it means the point where an update actually took place on the data structure, atomically
* `call` event happens when client attempt to change the data structure
* `ret` event happens when client receive the result of `call`

`linearization` need to happen between `call` and `ret` of the same thread, the idea is that given a history, we try to insert `linearization` point into the history as late as possible, example

a)T1 - Start Write A=2
b)T2 - Start Write A=3
c)T1 - Write A=2 done
d)T2 - Write A=3 done

Algo:

1. Found `a`, add to call set, state is now (sso, {a}, {})
2. Found `b`, add to call set, state is now (sso, {a, b}, {})
3. Found `c`, need to linearize, find all combination of `{a, b}`, and check if result matches sso
    - If any of the combination matches result, eg.
      apply `a then b` on `sso` would return `c and d` respectively, then it is linearizable
    - If none of the combination matches, backtrack to previous round and try a different JIT linearization
 
Insights: If a history is linearizable, it will have JIT linearization
A JIT linearizable history implies history is linearizable

So we just need to find JIT linearization, which in theory is a smaller set of all possible combination
 
# 23-26/09/2019

## What happened?
Enter a new sprint in a more relaxed pace

## How you feel?
Great, a lot more relax and finally have time to do what I enjoy in the evening, eg. doing nothing

## What have you learn?
* Backtracking is a technique that is inherently recursive, the idea is that given a configuration (just a vague notion of some state), an algorithm can try X number of path, we will try all path one by one recursively, if at any point we determine the path is no longer valid, we will return control to caller (which is the algorithm itself as it is recursive) and try a different path, backtracking is typically use when we are trying to find something in a large search space, and we can explore the space incrementally and determine it's validity before exhausting all possibility, as the act of backtrack means we skip a number of configuration. But it is hard to parallelize backtracking as recursion is inherently sequential, but we might be able to parallelize on the X number of path part, my gut instinct is that it wont be much faster as it might destroy cache efficiency
* Another point about backtracking: it is cleaner to implement backtracking with recursion, but it is not stack-safe, as backtracking by definition isn't tail recursive, there are ways to generically transform it into a iterative form, the technique is sometimes called simulated function, the basic idea is to manage stackframe on heap, effectively simulate how programming language implement functions call, this is almost guaranteed to be slower, then there's a paper on how to implement backtracking in a functional way which I am still reading
* Firehose is at least once delivery  
