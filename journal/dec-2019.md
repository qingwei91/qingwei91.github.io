# 01/12/2019
## What happened?
Went for a nice trip, been away for a while

## How you feel?
Great

## What have you learn?
* I get jealous over other's successes, not sure if it is jealousy or some sort of unsecure, but I need validation, be it external or internal
* I am motivated to learn, and thus I always try to build something that is relatively new to me to get the dopamine high when learning stuff, this helps me to be a better engineer but is a hindrance to actually build anything useful, I am a bit too lazy, I guess the solution is to be organized
* Su is insecure, I have yet found out how to help, but I am hoping we can make each other accountable so that we actually accomplish something, I think that is super important

# 27 / 12 / 2019

## What happened?

Having a long holiday, nothing much happened

## How you feel?

I was feeling lost and frustrated at one point because I am not sure what I want to do and I wasn't able to commit. But I believe I already overcome it and now I am focusing on learning stats by tackling a simple problem in NLP

## What have you learn?

To do NLP, the common flow is

1. Collect data
2. Convert data into some structured/semi structured way, eg. table
3. Form hypothesis about the problem
3. Convert data into useful representation that fits hypothesis, eg. BOW, TF-IDF, Word2Vec etc
3. Normalize the representation, ie. to make the sum of all features equal to 1, this allow our model not having to deal with different scale of features
4. Determine a model and apply the representation with the model
4. Remember to perform cross validation to reduce overfitting
4. Iterate based on result, check if hypothesis is correct

* One hot encoding is a technique to convert categorical variable (feature) into multiple binary variable, eg. `B out of (A, B, C)` => `{A: 0, B: 1, C: 0}`, this is done because most statistical model are only good at processing numeric value but not categorical values, and converting categorical value into multiple binary value allow us to preserve the independency between categorical data.
* The process of converting text into numeric representation for model processing is called feature extraction because machine learning model act of features
* Bags of word is a feature extraction technique to represent a document as a collections of words frequency, eg. `{I: 1, am: 1, Qing: 1}`, it is unordered and thus loses a lot of useful information from raw data, eg. how every word relates to each other
* `pandas.Dataframe.loc` can takes many different argument, one of it is a `Series` of Boolean where the size of Series equals to the x of Dataframe that can be used to update stuff conditionally


